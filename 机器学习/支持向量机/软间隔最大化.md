# 软间隔最大化

## 问题引入

实际上在大多数时候，数据的分布都不是线性可分的，而只是近似线性可分的，甚至很有可能是非线性的。现在我们暂不考虑非线性的情况，先来解决近似线性可分的情况。如果我们希望求解近似线性可分问题，就需要考虑更多限制条件。

我们可以对每个误分类点添加一个类似宽容度的东西来使得我们的SVM方法不那么笨拙死板，让它可以容忍那些分类结果不太理想的样本点（不能满足函数间隔大于等于 $1$ 的点），比如通过在问题中引入惩罚系数 $C$ 和松弛变量 $\pmb\xi$ 来达到这一点（假设有 $n$ 个样本点）。

$$
\begin{aligned}
    &\max_{\omega, b}\dfrac{1}{2}||\omega||^2 + C\sum_{i = 1}^n\xi_i\\
    st.&\ y_i(\pmb\omega^T\pmb x_i + b) \ge 1 - \xi_i\\
    &\xi_i\ge 0
\end{aligned}
$$

可以看到，松弛变量 $\xi_i$ 在容忍样本点在间隔内甚至误分类的情况下，对目标函数造成一定惩罚 $C\sum_{i = 1}^n\xi_i$。这样一来，（严格线性可分的）硬间隔问题几乎不痛不痒地转化为了（近似线性可分的）软间隔问题。

接下来我们就可以用相同的——即凸二次规划的——求解手段来解决这个问题。

## 解决问题

同样地写出拉格朗日函数

$$
F(\pmb\omega, b, \pmb\xi, \pmb\alpha, \pmb\mu) = \dfrac{1}{2}{||\pmb\omega||^2} - \sum_{i = 1}^n \alpha_iy_i[(\pmb\omega^T\pmb x_i + b) - 1 + \xi_i] +  C\sum_{i = 1}^n\xi_i - \sum_{i = 1}^n\mu_i\xi_i
$$

其中 $\alpha_i \ge 0, \mu_i \ge 0$。

仍然先将其写作一对对偶问题

$$
\begin{aligned}
    &\max_{\pmb\omega, b, \pmb\xi}\min_{\pmb\alpha, \pmb\mu} F(\pmb\omega, b, \pmb\xi, \pmb\alpha, \pmb\mu)\\
    &st. \alpha_i \ge 0,\ \mu_i \ge 0
\end{aligned}
$$

和

$$
\begin{aligned}
    &\min_{\pmb\alpha, \pmb\mu}\max_{\pmb\omega, b, \pmb\xi} F(\pmb\omega, b, \pmb\xi, \pmb\alpha, \pmb\mu)\\
    &st. \alpha_i \ge 0,\ \mu_i \ge 0
\end{aligned}
$$

然后同样地看第二个问题，对 $\pmb\omega, b$ 分别求导，我们会发现结果与硬间隔的情况相同

$$
\sum_{i = 1}^n\alpha_iy_i\pmb x_i = \pmb\omega\\
\sum_{i = 1}^n\alpha_iy_i = 0
$$

而对 $\xi_i$ 逐个求导则会得到一些约束条件

$$
C - \mu_i - \alpha_i = 0
$$

有了这个约束条件，我们实质上就能将接下来的极小问题变成只含 $\pmb\alpha$ 的一元函数。通过 $\mu_i\ge 0, \alpha_i\ge 0$，把 $\mu_i$ 消去

$$
C - \alpha_i \ge 0,\ \alpha_i \ge 0\Rightarrow 0 \le \alpha_i \le C
$$

经过化简，问题进一步变成

$$
\begin{aligned}
    &\min_{\pmb\alpha}\dfrac{1}{2}\sum_{i = 1}^n\sum_{j = 1}^n\alpha_i\alpha_jy_iy_j\pmb x_i^T\pmb x_j + \sum_{i = 1}^n\alpha_i\\
    st.&\  0 \le \alpha_i \le C\\
    & \sum_{i = 1}^n\alpha_iy_i = 0\\
\end{aligned}
$$

竟能如此相像？而且神奇的是，满足条件的最优解竟然恰好把 $\mu_i, \xi_i$ 全消掉了，最终多出的约束最优解范围的参数实际上只有 $C$。

这就很爽了，我们直接用完全类似硬间隔最大化的方法来求就行。

所以我们来考虑一下当前问题的 KKT 条件，设解为 $(\pmb\omega^*, b^*, \xi^*, \alpha^*, \mu^*)$，条件分为三组

（1）极值点必要条件（偏导为 $0$））

$$
\sum_{i = 1}^n\alpha_i^*y_i\pmb x_i = \pmb\omega^*\\
\sum_{i = 1}^n\alpha_i^*y_i = 0\\
C - \mu_i^* - \alpha_i^* = 0
$$

（2）不等式约束有解必要条件（不等式约束必须满足这些性质，有疑问可以看数学基础中的链接内容）

$$
\alpha_i^*[y_i({\pmb\omega^*}^T\pmb x_i + b) - 1 + \xi_i^*] = 0\\
\mu_i^*\xi_i^* = 0
$$

（3）凸二次规划问题本身的约束条件

$$
y_i({\pmb\omega^*}^T\pmb x_i + b) - 1 + \xi_i^* \ge 0\\
\xi_i^* \ge 0\\
\alpha_i^* \ge 0\\
\mu_i^* \ge 0
$$

> 注：以上所有 $i$ 满足 $i\in [1, N]$ 且 $i \in Z$。

一大坨东西，而我们的任务就是在大漠中淘金，别忘了我们的目标——寻求最终的解 $\omega^*, b^*$。

显而易见，$\pmb\omega$ 还是好求的

$$
\sum_{i = 1}^n\alpha_i^*y_i\pmb x_i = \pmb\omega^*
$$

据此可将分类超平面写成如下形式

$$
\sum_{i = 1}^n\alpha_i^*y_i(\pmb x_i\cdot\pmb x) + b = 0
$$

在核方法中我们将看到，这一表达将有助于我们解决更复杂的分类问题。

而 $b$ 就不那么显然了，注意到 $\mu_i^* \ge 0, \xi_i^*\ge 0$ 而 $\mu_i^* \xi_i^*= 0$，则 $\mu_i^*, \xi_i^*$ 中必定有一个为 $0$，同理 $\alpha_i^*, y_i(\pmb\omega^{*T}\pmb x_i + b) - 1 + \xi_i^*$ 中必有一个为 $0$。那么

* 若 $\alpha_i^*< C$，则必有 $\xi_i^* = 0$，此时对应的 $\pmb x_i$ 就是支持向量。
* 当 $\alpha_i^* = C,0 < \xi_i^* < 1$ 时 $\pmb x_i$ 分类正确，但落在间隔边界与超平面之间。
* 当 $\alpha_i^* = C, \xi_i^* > 1$ 时 $\pmb x_i$ 分类错误。
* 当 $\alpha_i^* = C, \xi_i^* = 1$ 时， $\pmb x_i$ 落在分类超平面上。

若存在 $0 < \alpha_j^* < C$，则有 $y_i(\pmb\omega^{*T} + b) - 1 = 0$，即

$$
b = y_i - \sum_{i = 1}^n\alpha_i^*y_i(\pmb x_i\cdot\pmb x_j)
$$

> 注意：由于 $b$ 对于该问题是唯一的，因此只要得知任意一个 $\alpha_j, 0 < \alpha_j < C$，即可计算 $b$。注意，此处我们已经假设 $\pmb\alpha$ 已经解出而略去了求解它的部分。