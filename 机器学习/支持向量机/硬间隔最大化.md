# 硬间隔最大化SVM

## 问题引入

我们将用 SVM 解决的问题，与我们在感知机中看到的是一致的——给定一组输入空间上的点集 $\{(\pmb x_i, y_i)\}_{i = 1}^n, \pmb x_i\in R^n, y_i\in \{+1, -1\}$，希望找到一个分类超平面 $f(x) = \text{sgn}(\pmb\omega^T\pmb x + b)$，将 $y = +1$ 的点和 $y = -1$ 的点正确分开。

让我们回忆一下感知机的解决思路，它通过构造一个函数来表达所有误分类点到分类超平面的几何距离，并最小化这个距离来寻找最好的超平面参数。这种方法有一个缺陷，即它找到的分类超平面可能泛化能力比较差（可能离某类点更近，因为这类点中误分类点较多），此外，由它为基本模型构建的神经网络的可解释性也不是那么好。

SVM 致力于解决这个问题，它实质上是将上述问题归结到一个凸优化问题，并借助最优化理论的解决方法来解决问题，因此它具有良好的数学结构，同时由于求解过程的清晰性，它具备相当好的可解释性。

我们在[SVM及其数学基础](./SVM及其数学基础.md)中也提到过，SVM其实就是在解决一个凸优化问题，因此我们核心的解决思路其实相当明晰：

（1）将上述分类问题转换成一个凸优化问题。
（2）使用凸优化的求解方法求解该凸优化问题。
（3）寻找更好的算法以降低求解复杂度。

## 问题转化

我们首先来考虑一个最优的分类超平面应该具有什么样性质，显然，它首先要尽可能地将所有点正确分类，我们需要找到一个合适的标准来进行评判。现在，我们不妨从最简单的严格线性可分的分类问题入手来考虑这个问题。

严格线性可分的分类问题中，我们一定可以找到一些分类超平面完全把两类点分开，即把它们正确的分类。所以我们现在的任务是进一步考虑，要选择其中泛化性能最优秀的作为我们的答案。在这个问题中，不难发现根据仅有的信息，**最优的超平面一定是恰好在两类点的正中间的**，这也就是 SVM 给出的评判标准。

SVM 为了描述一个恰好在两类点正中间的分类超平面，首先引入了两个概念——函数间隔和几何间隔，我们先对它们进行适当的考察。

### 函数间隔



### 几何间隔