# 感知机、神经元到全连接网络

## 写在前面

感知机是神经网络和支持向量机的基础，它是一个线性分类器，可以作为神经网络的一个最简单神经元（后续还有更复杂的神经元形式），也可以作为支持向量机的基础模型。

全连接网络是最简单的神经网络，是神经网络的基本范式，其它复杂的神经网络基本都是基于全连接网络发展而来的。

## 感知机

感知机是一个二分类线性分类模型，输入为样本的特征向量，输出为样本的类别，方法是在空间中找到一个将二类分离的超平面。为了寻求最优超平面的参数，仍然使用梯度下降法最小化关于误分类信息的损失函数。

### 感知机结构和定义

假设特征空间为 $\mathcal{X}\subset R^n$，输出空间 $\mathcal{Y} = \{1, -1\}$，样本特征向量 $\pmb{x}\in \mathcal X$，输出 $y\in \mathcal Y$ 表示样本类别。假设空间的一个函数

$$
f(x) = \text{sign}(\pmb\omega \cdot \pmb x + b)
$$

称为感知机。其中 $\pmb\omega（权值）, b$ （偏置）为模型参数，$\text{sign}$ 是符号函数。

![Screenshot-from-2022-11-11-04-37-32.png](http://image.tjzfile.xyz/images/2022/11/11/Screenshot-from-2022-11-11-04-37-32.png)

有了分类模型，接下来就要考虑如何进行模型学习了。首先必须考虑模型学习需要优化的损失函数，它必须易求且可微，然后就是考虑优化它的方法。

> 注：
> （1）线性可分：如果数据集中的正例和反例可以被一个超平面完全分离，那么这个数据集就是线性可分的。

### 感知机学习策略

由于我们必须找到一个关于参数 $\pmb\omega, b$ 可微的损失函数，所以将它们都用上是最好的方案，显然超平面在空间中的位置特性是与参数强相关的，故应首先考虑位置关系，那么距离是一个好的选择。

根据点到直线的距离公式，容易推得任意点到超平面的距离

$$
l(\pmb x_0) = \dfrac{|\pmb\omega\cdot\pmb x_0 + b|}{||\pmb\omega||}
$$

而且，对于误分类的数据 $(\pmb x_i,y_i)$，分类器所得类别与真实类别相反，即必然有

$$
-y_i(\pmb\omega\cdot\pmb x_i + b) > 0
$$

更进一步，由于任意 $|y_i| = 1$，所以误分类点到超平面的距离为

$$
-\dfrac{1}{||\pmb\omega||}y_i(\pmb\omega\cdot\pmb x_i + b)
$$

则所有误分类点到超平面的总距离

$$
-\dfrac{1}{||\pmb\omega||}\sum_{\pmb x_i\in M}y_i(\pmb\omega\cdot \pmb x_i + b)
$$

其中 $M$ 为所有误分类点的集合，它对于所有误分类点可导。

不考虑 $\dfrac{1}{||\pmb\omega||}$，取

$$
L(\pmb\omega;b) = -\sum_{\pmb x_i\in M}y_i(\pmb\omega\cdot \pmb x_i + b)
$$

作为感知机的损失函数。

### 感知机学习方法

由于批量梯度下降可能存在样本对损失的贡献相互抵消从而导致模型无法很好收敛的问题，感知机学习方法采用随机梯度下降，每轮只随机取一个样本进行梯度下降。

假设随机选取的误分类点为 $(x_i, y_i)$，直接求导可得

$$
\dfrac{\partial L}{\partial\pmb\omega} = -x_iy_i
$$

$$
\dfrac{\partial L}{\partial b} = -y_i
$$

那么每次参数更新为

$$
\pmb\omega \leftarrow \pmb\omega + \eta \pmb x_iy_i
$$

$$
b \leftarrow b + \eta y_i
$$

> 注：
>（1）可以期待在线性可分的数据集上，梯度下降一定会在有限步后收敛，得到一个分离超平面（Novikoff定理）。
>（2）感知机学习算法存在对偶形式，即将训练集各点误分类次数作为参数进行训练。

## 神经元模型

* 典型的神经元是MP神经元，它被用于全连接神经网络中，它通过一个仿射函数接收输入信号，经过一个激活函数变换后进行输出。

![Screenshot-from-2022-11-11-05-13-06.png](http://image.tjzfile.xyz/images/2022/11/11/Screenshot-from-2022-11-11-05-13-06.png)

