# 集成学习

集成学习通过构建并结合多个学习器来完成学习任务，它能通过组合多个弱学习器来构建一个强学习器，它基于如下定理

> 弱可学习是强可学习的充要条件。

它的结构如下

![QQ20230123182557.png](http://image.tjzfile.xyz/images/2023/01/23/QQ20230123182557.png)

其中**个体学习器**可以有多种不同的选择

* 若学习器都是同类（如都是感知机）的，则该集成称为同质集成，其中学习器称为基学习器。
* 若学习器是不同类的（如决策树、感知机、神经网络的混合），则改集成称为异质集成，其中学习器称为组件学习器。

**结合模块**也有多种不同的策略

* 平均法：用于数值型输出，有简单平均、加权平均等。
* 投票法：用于分类，有绝对多数投票、相对多数投票、加权投票等。
* 学习法：用于训练数据较多较复杂时，如 Stacking。

而对于不同集成方法，又有不同的**学习器生成策略**

* 并行化：个体学习器间不存在依赖和先后关系，可同时生成，如 Bagging 和随机森林。
* 串行化：个体学习器间存在依赖关系，后生成的学习器依赖之前生成的，比如 Boosting。

不难发现，集成结果的好坏与学习器和结合模块的选择有关

* 一般来说在同质集成下，随着学习器的数目的增加，集成的错误率将指数级下降，最终趋于 $0$。
* 不同的学习器应在同一特征空间的不同部分具有良好的拟合能力，以提高集成对整个特征空间的预测性能（学习器应做到准确性和多样性并存）。