# 模型评估与选择

## 基本概念

### 误差

* 有训练误差（经验误差）、测试误差（泛化误差）两种，顾名思义即可。

### 过拟合

选择或学习一个合适的模型，并且如果在假设空间中存在“真”模型，那么所选择的模型应该逼近真模型，但是一般情况下我们无法获取假设空间的全部数据用于拟合来逼近这个模型。对于假设空间中部分数据的拟合结果，如果它越接近这部分数据的分布，它越有可能具有更低的泛化能力。

* 训练误差小但测试误差大，就很有可能发生了过拟合。这是不那么令人满意的结果。
* 一般来说，过拟合的模型复杂度更高些（参数更多）。

下图中，绿线代表过拟合的模型，黄线代表欠拟合的模型，黑线是假想的真模型。

> 注：一般来说，过拟合的模型会在训练误差小到一定程度时，测试误差不断增大。

![Screenshot-from-2022-10-03-00-22-13.png](http://image.tjzfile.xyz/images/2022/10/03/Screenshot-from-2022-10-03-00-22-13.png)

* 通常通过正则化，或说是添加正则项来解决这个问题，正则化添加的惩罚与模型复杂度成正比，使得模型选择使经验风险和结构风险同时最小的模型。


### 精度

通常通过如下式子计算

$$
acc = \dfrac{1}{m}\sum_{i = 1}^m I(y_i = f(\pmb x_i))
$$

当 $y_i = f(x_i)$ 时，$I$ 为 $1$，否则为 $0$。

## 正则化

正则化是结构风险最小策略的实现，在正常的损失函数上加一个惩罚项就是。

$$
E(Y, f(X)) = \sum_{i = 1}^m L(Y, f(X)) + \lambda g(f)
$$

$\lambda||f||_l$ 就是惩罚项，或称为正则项（其中 $\lambda$ 为惩罚系数，是常数）。一般来说，正则项 $g(f)$ 是一个关于模型 $f$ 的复杂度的单调递增函数。

前面提到，模型的复杂度的一个显性表征即是模型参数的个数，因此不妨设 $g(f) = ||\pmb {\hat\omega}||_l$，即参数向量的 $l$ 范数。

向量的各阶范数分别有以下特征：

* $0$ 范数：向量中非 $0$ 元素的个数。
* $1$ 范数：向量中各个元素的绝对值之和。
* $2$ 范数：向量中各个元素的平方和。

> 注：选取 $0, 1$ 范数使得 $\pmb{\hat\omega}$ 的分量中 $0$ 分量尽可能多，$2$ 范数使得各分量更均匀。

添加二范数正则项，将使多元线性回归问题变得一定可解。
## 验证方法

* 为了避免过拟合，也可以在训练集上做一些工作，即在训练过程中引入验证集用以优化参数。
* 在学习到的不同模型中，选择对验证集有最小预测误差的模型，这也意味着这些验证方法往往要求训练多次。

> 注：由于实际上并没有在验证集上进行训练，验证集的评估结果是作为测试误差来看待的。

### 留出法

* 直接将训练集拆成两个互斥集部分。这种方法往往是最常用的。
* 为了更好的训练效果，往往还需要满足数据乱序、样本按权平均分配的条件，这保证了数据分布的一致性。

一般直接通过乱序分层采样解决这一问题，简单来说就是调个api打乱一下数据然后按样本各类别比例均匀分配数据至训练集和测试集。比如，若正例和反例各占 $50%$，那么对于 $1000$ 个样本的 $80\%:20\%$ 划分，训练集应分到 $400$ 个正例，$400$ 个反例。

## 性能度量和分析